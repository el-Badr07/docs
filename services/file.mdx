---
title: "File Service"
description: "Comprehensive file management service for document uploads, storage, and lifecycle management in Textra"
---

The File Service provides comprehensive file management capabilities for Textra's document processing workflows. It handles secure file uploads, organized storage, metadata management, integrity verification, and automated cleanup with support for multiple document types and lifecycle management.

## Service Architecture

### Core Components

The File Service manages document storage with organized directory structure:

```python
class FileService:
    def __init__(self, base_upload_dir: str = "uploads"):
        self.base_upload_dir = Path(base_upload_dir)
        self.base_upload_dir.mkdir(parents=True, exist_ok=True)
```

### Directory Structure

The service organizes files into **6 specialized subdirectories**:

1. **invoices**: Invoice documents and receipts
2. **bank_statements**: Bank statements and financial records
3. **payroll**: Payroll documents and employee records
4. **receipts**: Expense receipts and cash receipts
5. **general**: Other financial documents and miscellaneous files
6. **temp**: Temporary files for processing

```python
self.subdirs = {
    "invoices": self.base_upload_dir / "invoices",
    "bank_statements": self.base_upload_dir / "bank_statements",
    "payroll": self.base_upload_dir / "payroll",
    "receipts": self.base_upload_dir / "receipts",
    "general": self.base_upload_dir / "general",
    "temp": self.base_upload_dir / "temp"
}
```

### Document Type Mapping

The service intelligently maps document types to appropriate directories:

```python
type_mapping = {
    "invoice": "invoices",
    "bank_statement": "bank_statements",
    "payroll_document": "payroll",
    "expense_receipt": "receipts",
    "cash_receipt": "receipts",
    "supplier_statement": "general",
    "customer_payment": "general",
    "loan_document": "general",
    "insurance_document": "general",
    "utility_bill": "general",
    "government_document": "general",
    "other": "general"
}
```

## Core Methods

### Upload Directory Management

```python
def get_upload_directory(self, document_type: str) -> Path:
    """Get the appropriate upload directory for a document type."""
```

Returns the correct storage directory based on document type, ensuring organized file management and easy retrieval.

### File Upload Processing

```python
async def save_uploaded_file(
    self,
    file: UploadFile,
    document_type: str,
    invoice_id: Optional[str] = None,
    user_id: Optional[str] = None
) -> Dict[str, Any]:
```

**Upload Process:**
1. Determines appropriate upload directory based on document type
2. Generates unique filename with timestamp and optional invoice ID
3. Reads and validates file content
4. Calculates SHA-256 hash for integrity verification
5. Saves file with appropriate permissions
6. Returns comprehensive file metadata

**Filename Generation:**
```python
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
file_extension = Path(file.filename).suffix if file.filename else ""

if invoice_id:
    filename = f"{invoice_id}_{timestamp}_{document_type}{file_extension}"
else:
    filename = f"{timestamp}_{document_type}{file_extension}"
```

**File Information Response:**
```json
{
  "filename": "INV-12345678-231201_20240115_103000_invoice.pdf",
  "original_filename": "invoice.pdf",
  "file_path": "/uploads/invoices/INV-12345678-231201_20240115_103000_invoice.pdf",
  "relative_path": "invoices/INV-12345678-231201_20240115_103000_invoice.pdf",
  "file_size": 1024000,
  "file_hash": "a1b2c3d4e5f6789...",
  "mime_type": "application/pdf",
  "document_type": "invoice",
  "invoice_id": "INV-12345678-231201",
  "user_id": "user123",
  "upload_timestamp": "2024-01-15T10:30:00Z",
  "upload_directory": "/uploads/invoices"
}
```

## File Retrieval and Management

### File Content Access

```python
def get_file_content(self, file_path: str) -> Optional[bytes]:
    """Get file content by path."""
```

Safely retrieves file content with error handling and existence verification.

### File Information Retrieval

```python
def get_file_info(self, file_path: str) -> Optional[Dict[str, Any]]:
    """Get file information."""
```

Returns comprehensive file metadata:

```json
{
  "filename": "invoice.pdf",
  "file_path": "/uploads/invoices/invoice.pdf",
  "file_size": 1024000,
  "created_time": "2024-01-15T10:30:00Z",
  "modified_time": "2024-01-15T10:30:00Z",
  "mime_type": "application/pdf",
  "exists": true
}
```

### File Operations

```python
def delete_file(self, file_path: str) -> bool:
    """Delete a file."""

def move_file(self, source_path: str, destination_path: str) -> bool:
    """Move a file from source to destination."""
```

**Move File Features:**
- Creates destination directory if needed
- Preserves file metadata
- Handles cross-directory moves
- Provides error handling and logging

## File Validation and Security

### File Type Validation

```python
def validate_file_type(self, filename: str, allowed_extensions: List[str]) -> bool:
    """Validate file type against allowed extensions."""
```

**Supported File Types:**
- **PDF**: Primary document format
- **Images**: JPG, JPEG, PNG, TIFF, BMP, GIF
- **Office**: DOC, DOCX, XLS, XLSX
- **Text**: TXT, CSV
- **Archives**: ZIP, RAR (for batch uploads)

### Integrity Verification

The service uses SHA-256 hashing for file integrity:

```python
# Calculate file hash for integrity checking
file_hash = hashlib.sha256(content).hexdigest()
```

Benefits:
- Detect file corruption
- Prevent duplicate uploads
- Verify successful transfers
- Audit trail maintenance

## Temporary File Management

### Temporary File Creation

```python
def get_temp_file_path(self, filename: str) -> Path:
    """Get path for temporary file."""
```

Creates unique temporary file paths for processing workflows.

### Temporary File Cleanup

```python
def cleanup_temp_files(self, older_than_hours: int = 24) -> int:
    """Clean up temporary files older than specified hours."""
```

**Cleanup Features:**
- Automatic removal of old temporary files
- Configurable retention periods
- Logging of cleanup operations
- Error handling for locked files

## Storage Management

### Directory Statistics

```python
def get_directory_stats(self) -> Dict[str, Any]:
    """Get statistics for all subdirectories."""
```

Returns comprehensive storage statistics:

```json
{
  "base_directory": "/uploads",
  "total_files": 1250,
  "total_size_bytes": 5368709120,
  "total_size_human": "5.0 GB",
  "subdirectory_stats": {
    "invoices": {
      "file_count": 856,
      "total_size": 3221225472,
      "size_human": "3.0 GB",
      "avg_file_size": 3762176
    },
    "bank_statements": {
      "file_count": 124,
      "total_size": 536870912,
      "size_human": "512 MB",
      "avg_file_size": 4330883
    },
    "receipts": {
      "file_count": 203,
      "total_size": 805306368,
      "size_human": "768 MB",
      "avg_file_size": 3966192
    },
    "payroll": {
      "file_count": 45,
      "total_size": 268435456,
      "size_human": "256 MB",
      "avg_file_size": 5965232
    },
    "general": {
      "file_count": 22,
      "total_size": 536870912,
      "size_human": "512 MB",
      "avg_file_size": 24403223
    }
  },
  "last_updated": "2024-01-15T10:30:00Z"
}
```

### Automated Cleanup

```python
def cleanup_old_files(self, older_than_days: int = 30) -> int:
    """Clean up files older than specified number of days."""
```

**Cleanup Policy:**
- Default retention: 30 days for processed files
- Configurable retention periods per document type
- Archive important documents before deletion
- Comprehensive logging of cleanup operations

**Cleanup Results:**
```json
{
  "files_deleted": 45,
  "space_freed_bytes": 1073741824,
  "space_freed_human": "1.0 GB",
  "directories_processed": [
    "invoices",
    "bank_statements",
    "receipts",
    "payroll",
    "general",
    "temp"
  ],
  "cleanup_timestamp": "2024-01-15T10:30:00Z"
}
```

## MIME Type Detection

The service provides intelligent MIME type detection:

```python
import mimetypes

# Automatic MIME type detection
mime_type = file.content_type or mimetypes.guess_type(filename)[0]
```

**Supported MIME Types:**
- `application/pdf`: PDF documents
- `image/jpeg`, `image/png`: Image files
- `application/vnd.openxmlformats-officedocument.spreadsheetml.sheet`: Excel files
- `text/csv`: CSV files
- `application/zip`: Archive files

## Error Handling

The File Service implements comprehensive error handling:

```python
class FileServiceError(Exception):
    """Base exception for file service errors."""

class FileNotFoundError(FileServiceError):
    """Raised when requested file doesn't exist."""

class InvalidFileTypeError(FileServiceError):
    """Raised when file type is not allowed."""

class InsufficientStorageError(FileServiceError):
    """Raised when storage space is insufficient."""
```

### Error Recovery

- **Partial upload recovery**: Resume interrupted uploads
- **Corruption detection**: Verify file integrity after operations
- **Automatic retry**: Retry failed operations with exponential backoff
- **Graceful degradation**: Continue operations despite individual failures

## Performance Optimization

### Async Operations

All file operations support asynchronous execution:

```python
async def save_uploaded_file(...) -> Dict[str, Any]:
    # Non-blocking file operations
    content = await file.read()
    
    # Async file writing
    with open(file_path, "wb") as f:
        f.write(content)
```

### Memory Management

- **Streaming uploads**: Handle large files without memory exhaustion
- **Chunked processing**: Process files in manageable chunks
- **Temporary file cleanup**: Automatic cleanup prevents disk overflow
- **Memory monitoring**: Track memory usage during operations

## Integration with Other Services

### Database Integration

File metadata is stored in MongoDB:

```python
# Store file information in database
file_record = await db_service.store_document_upload(file_info)
```

### Processing Pipeline Integration

Files flow seamlessly into the processing pipeline:

```python
# File upload triggers processing
processing_id = await accounting_service.process_invoice(file_path)
```

### Cache Integration

File metadata cached for fast access:

```python
# Cache file information
await cache_service.cache_file_info(file_path, file_info)
```

## Service Initialization

### Singleton Pattern

```python
# Global file service instance
_file_service = None

def get_file_service() -> FileService:
    """Get singleton file service instance."""
    global _file_service
    if _file_service is None:
        base_dir = os.environ.get("UPLOAD_BASE_DIR", "uploads")
        _file_service = FileService(base_upload_dir=base_dir)
    return _file_service
```

### Configuration

Environment-based configuration:

```python
# Storage configuration
UPLOAD_BASE_DIR = os.environ.get("UPLOAD_BASE_DIR", "uploads")
MAX_FILE_SIZE = int(os.environ.get("MAX_FILE_SIZE", "52428800"))  # 50MB
ALLOWED_EXTENSIONS = os.environ.get("ALLOWED_EXTENSIONS", "pdf,jpg,jpeg,png,xlsx,csv").split(",")

# Cleanup configuration
CLEANUP_RETENTION_DAYS = int(os.environ.get("CLEANUP_RETENTION_DAYS", "30"))
TEMP_FILE_RETENTION_HOURS = int(os.environ.get("TEMP_FILE_RETENTION_HOURS", "24"))
```
